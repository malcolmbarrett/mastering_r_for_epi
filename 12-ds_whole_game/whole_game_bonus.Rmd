---
title: "Modeling survival on the Titanic"
output: html_document
---

## Bonus: Machine Learning

R has excellent support for many other approaches to modeling. Two such packages are `rms`, focused on regression, and `caret`, focused on machine learning. If you're interested in machine learning, give this optional section a try. It may take a while to run, so try using the `cache` chunk option to store computationally heavy chunks between knittings. (Be careful not to cache chunks that output plots; do those in separate chunks, otherwise the figure won't update in a predictable manner.)

```{r setup, message=FALSE}
library(tidyverse)
library(haven)
library(mice)
titanic <- read_dta("titanic3.dta")
titanic <- titanic %>%
  mutate(
    survived = factor(survived, labels = c("Died", "Survived")),
    pclass = factor(pclass)
  )
titanic <- titanic %>%
  mutate(
    title = str_replace_all(name, "(.*, )|(\\..*)", ""),
    title = case_when(
      title %in% c("Mlle", "Ms") ~ "Miss",
      title == "Mme" ~ "Mrs",
      TRUE ~ title
    ),
    title = factor(title)
  )
titanic <- titanic %>%
  mutate(title = fct_lump(title, 4))
knitr::opts_chunk$set(echo = TRUE)
```

Install the packages if you don't have them. Uncomment the code to be able to run it. If you re-knit, remember to comment it back out so you don't keep re-installing the packages every time. 

```{r}
# install.packages(c("caret", "rms", "randomForest", "gbm))
library(caret)
library(rms)
```

You can save formulas directly so that you don't need to keep re-entering them. We'll save the above formula as `fmla`. We'll also use a formula for a non-linear model that uses `rcs()` to fit a restricted cubic spline on `age` and quadratic terms for the `sibsp` and `parch` variables. These are count variables, which do better with quadratics than with spline terms.

```{r}
fmla <- survived ~ mice_age + pclass + sibsp + parch + mice_embarked + title
fmla_spline <- survived ~ rcs(mice_age) + pclass + sibsp + I(sibsp^2) + parch + I(parch^2) + mice_embarked + title
```

We need to re-impute age first.

```{r}
imputed_titanic <- titanic %>%
  select(age, pclass, sex, sibsp, parch, embarked, title) %>%
  # remove labels because mice doesn't like them
  purrr::map_df(haven::zap_labels) %>% 
  mice(method = "norm") %>%
  complete()

titanic$mice_age <- imputed_titanic$age
titanic$mice_embarked <- imputed_titanic$embarked
```

We'll also create a function so we don't have to keep entering arguments. We'll cover functions in more depth tomorrow. This one wraps around the `train()` function from the caret package, which fits many types of models. Our custom function is called `ml()`. You can use it to set the formula or method, as well as pass any other arguments to `train` that you want. 

`ml()` will fit a model with the specified model and get model metrics using repeated cross-validation. It will also automatically tune the more complicated machine learning algorithms.

```{r}
#  function to avoid setting defaults repeatedly
ml <- function(.fmla = fmla, method, ...) {
  train(
    .fmla,
    # set data to titanic
    data = titanic,
    # the method we'll use
    method = method,
    # any extra arguments we need
    ...,
    # remove missing values
    na.action = na.omit,
    # use the area under the curve to measure model performance
    metric = "ROC",
    # use repeated cross-validation
    trControl = trainControl(
      method = "repeatedcv",
      repeats = 5,
      summaryFunction = twoClassSummary,
      classProbs = TRUE
    )
  )
}
```

We're going to fit models using four approaches: the same logistic regression as above, a logistic regression with the non-linear model, a random forest model, and a gradient boosted model. Run each and check the results. How do the ROC values look? This is only one way to measure model performance, but the closer the value to 1, the better the predictive ability.

How about the sensitivity and specificity? What's the trade off?

```{r}
logistic <- ml(method = "glm", family = binomial)
logistic
```

```{r}
logistic_spline <- ml(fmla_spline, method = "glm", family = binomial)
logistic_spline
```

```{r}
random_forest <- ml(fmla_spline, method = "rf", family = binomial)
random_forest
```

```{r}
boosted <- ml(fmla_spline, method = "gbm")
boosted
```

The caret package also has a built-in function for variable importance, `varImp()`. It returns a data frame. Run the code below to sort it. Which is the most important variable? Is the highest ranking variable different than from the logistic model?

```{r}
library(gbm)
boosted$finalModel %>%
  varImp() %>%
  rownames_to_column("variable") %>%
  arrange(desc(Overall))
```
ng the `cache` code chunk option to save the results from knit to knit.

Install the packages if you don't have them. Uncomment the code to be able to run it. If you re-knit, remember to comment it back out so you don't keep re-installing the packages every time. 
